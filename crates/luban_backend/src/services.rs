use anyhow::{Context as _, anyhow};
use bip39::Language;
use luban_domain::paths;
use luban_domain::{
    AttachmentKind, AttachmentRef, CodexThreadEvent, CodexThreadItem, ContextImage,
    ConversationEntry, ConversationSnapshot, CreatedWorkspace, PersistedAppState,
    ProjectWorkspaceService, PullRequestCiState, PullRequestInfo, PullRequestState,
    RunAgentTurnRequest,
};
use rand::{Rng as _, rngs::OsRng};
use std::{
    collections::HashSet,
    path::PathBuf,
    process::Command,
    sync::Arc,
    sync::atomic::{AtomicBool, Ordering},
    time::{Instant, SystemTime, UNIX_EPOCH},
};

use crate::sqlite_store::{SqliteStore, SqliteStoreOptions};

mod codex_cli;
mod context_blobs;
mod conversations;
mod git;
mod task;
use codex_cli::CodexTurnParams;

fn contains_attempt_fraction(text: &str) -> bool {
    let mut chars = text.chars().peekable();
    while let Some(ch) = chars.next() {
        if !ch.is_ascii_digit() {
            continue;
        }

        while matches!(chars.peek(), Some(next) if next.is_ascii_digit()) {
            let _ = chars.next();
        }

        if !matches!(chars.peek(), Some('/')) {
            continue;
        }
        let _ = chars.next();

        if !matches!(chars.peek(), Some(next) if next.is_ascii_digit()) {
            continue;
        }
        return true;
    }

    false
}

fn is_transient_reconnect_notice(message: &str) -> bool {
    let message = message.trim();
    if message.is_empty() {
        return false;
    }

    let lower = message.to_ascii_lowercase();
    if !lower.contains("reconnecting") {
        return false;
    }

    contains_attempt_fraction(&lower)
}

fn codex_item_id(item: &CodexThreadItem) -> &str {
    match item {
        CodexThreadItem::AgentMessage { id, .. } => id,
        CodexThreadItem::Reasoning { id, .. } => id,
        CodexThreadItem::CommandExecution { id, .. } => id,
        CodexThreadItem::FileChange { id, .. } => id,
        CodexThreadItem::McpToolCall { id, .. } => id,
        CodexThreadItem::WebSearch { id, .. } => id,
        CodexThreadItem::TodoList { id, .. } => id,
        CodexThreadItem::Error { id, .. } => id,
    }
}

fn qualify_codex_item(turn_scope_id: &str, item: CodexThreadItem) -> CodexThreadItem {
    let raw_id = codex_item_id(&item);
    if raw_id.starts_with(turn_scope_id) {
        return item;
    }

    let qualified_id = format!("{turn_scope_id}/{raw_id}");
    match item {
        CodexThreadItem::AgentMessage { id: _, text } => CodexThreadItem::AgentMessage {
            id: qualified_id,
            text,
        },
        CodexThreadItem::Reasoning { id: _, text } => CodexThreadItem::Reasoning {
            id: qualified_id,
            text,
        },
        CodexThreadItem::CommandExecution {
            id: _,
            command,
            aggregated_output,
            exit_code,
            status,
        } => CodexThreadItem::CommandExecution {
            id: qualified_id,
            command,
            aggregated_output,
            exit_code,
            status,
        },
        CodexThreadItem::FileChange {
            id: _,
            changes,
            status,
        } => CodexThreadItem::FileChange {
            id: qualified_id,
            changes,
            status,
        },
        CodexThreadItem::McpToolCall {
            id: _,
            server,
            tool,
            arguments,
            result,
            error,
            status,
        } => CodexThreadItem::McpToolCall {
            id: qualified_id,
            server,
            tool,
            arguments,
            result,
            error,
            status,
        },
        CodexThreadItem::WebSearch { id: _, query } => CodexThreadItem::WebSearch {
            id: qualified_id,
            query,
        },
        CodexThreadItem::TodoList { id: _, items } => CodexThreadItem::TodoList {
            id: qualified_id,
            items,
        },
        CodexThreadItem::Error { id: _, message } => CodexThreadItem::Error {
            id: qualified_id,
            message,
        },
    }
}

fn qualify_event(turn_scope_id: &str, event: CodexThreadEvent) -> CodexThreadEvent {
    match event {
        CodexThreadEvent::ItemStarted { item } => CodexThreadEvent::ItemStarted {
            item: qualify_codex_item(turn_scope_id, item),
        },
        CodexThreadEvent::ItemUpdated { item } => CodexThreadEvent::ItemUpdated {
            item: qualify_codex_item(turn_scope_id, item),
        },
        CodexThreadEvent::ItemCompleted { item } => CodexThreadEvent::ItemCompleted {
            item: qualify_codex_item(turn_scope_id, item),
        },
        other => other,
    }
}

fn generate_turn_scope_id() -> String {
    let micros = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_micros();
    let rand: u64 = OsRng.r#gen();
    format!("turn-{micros:x}-{rand:x}")
}

fn resolve_luban_root() -> anyhow::Result<PathBuf> {
    if let Some(root) = std::env::var_os(paths::LUBAN_ROOT_ENV) {
        let root = root.to_string_lossy();
        let trimmed = root.trim();
        if trimmed.is_empty() {
            return Err(anyhow!("{} is set but empty", paths::LUBAN_ROOT_ENV));
        }
        return Ok(PathBuf::from(trimmed));
    }

    if cfg!(test) {
        let nanos = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos();
        let pid = std::process::id();
        return Ok(std::env::temp_dir().join(format!("luban-test-{pid}-{nanos}")));
    }

    let home = std::env::var_os("HOME").ok_or_else(|| anyhow!("HOME is not set"))?;
    Ok(PathBuf::from(home).join("luban"))
}

#[derive(Clone)]
pub struct GitWorkspaceService {
    worktrees_root: PathBuf,
    conversations_root: PathBuf,
    sqlite: SqliteStore,
}

impl GitWorkspaceService {
    pub fn new() -> anyhow::Result<Arc<Self>> {
        Self::new_with_options(SqliteStoreOptions::default())
    }

    pub fn new_with_options(options: SqliteStoreOptions) -> anyhow::Result<Arc<Self>> {
        let luban_root = resolve_luban_root()?;

        std::fs::create_dir_all(&luban_root)
            .with_context(|| format!("failed to create {}", luban_root.display()))?;

        let worktrees_root = paths::worktrees_root(&luban_root);
        let conversations_root = paths::conversations_root(&luban_root);
        let sqlite_path = paths::sqlite_path(&luban_root);
        let sqlite = SqliteStore::new_with_options(sqlite_path, options)
            .context("failed to init sqlite store")?;

        Ok(Arc::new(Self {
            worktrees_root,
            conversations_root,
            sqlite,
        }))
    }

    fn generate_workspace_name(&self) -> anyhow::Result<String> {
        let words = Language::English.word_list();
        let mut rng = OsRng;
        let w1 = words[rng.gen_range(0..words.len())];
        let w2 = words[rng.gen_range(0..words.len())];
        Ok(format!("{w1}-{w2}"))
    }

    fn worktree_path(&self, project_slug: &str, workspace_name: &str) -> PathBuf {
        let mut path = self.worktrees_root.clone();
        path.push(project_slug);
        path.push(workspace_name);
        path
    }

    fn codex_executable(&self) -> PathBuf {
        std::env::var_os(paths::LUBAN_CODEX_BIN_ENV)
            .map(PathBuf::from)
            .unwrap_or_else(|| PathBuf::from("codex"))
    }

    fn run_codex_turn_streamed_via_cli(
        &self,
        params: CodexTurnParams,
        cancel: Arc<AtomicBool>,
        on_event: impl FnMut(CodexThreadEvent) -> anyhow::Result<()>,
    ) -> anyhow::Result<()> {
        let codex = self.codex_executable();
        codex_cli::run_codex_turn_streamed_via_cli(&codex, params, cancel, on_event)
    }
}

impl ProjectWorkspaceService for GitWorkspaceService {
    fn load_app_state(&self) -> Result<PersistedAppState, String> {
        self.load_app_state_internal().map_err(|e| format!("{e:#}"))
    }

    fn save_app_state(&self, snapshot: PersistedAppState) -> Result<(), String> {
        self.save_app_state_internal(snapshot)
            .map_err(|e| format!("{e:#}"))
    }

    fn create_workspace(
        &self,
        project_path: PathBuf,
        project_slug: String,
    ) -> Result<CreatedWorkspace, String> {
        let result: anyhow::Result<CreatedWorkspace> = (|| {
            let remote = self.select_remote(&project_path)?;

            self.run_git(&project_path, ["fetch", "--prune", &remote])
                .with_context(|| format!("failed to fetch remote '{remote}'"))?;

            let upstream_ref = self.resolve_default_upstream_ref(&project_path, &remote)?;

            std::fs::create_dir_all(self.worktrees_root.join(&project_slug))
                .context("failed to create worktrees root")?;

            for _ in 0..64 {
                let workspace_name = self.generate_workspace_name()?;
                let branch_name = format!("luban/{workspace_name}");
                let worktree_path = self.worktree_path(&project_slug, &workspace_name);

                if worktree_path.exists() {
                    continue;
                }

                let branch_ref = format!("refs/heads/{branch_name}");
                let branch_exists = Command::new("git")
                    .args(["show-ref", "--verify", "--quiet", &branch_ref])
                    .current_dir(&project_path)
                    .status()
                    .ok()
                    .map(|s| s.success())
                    .unwrap_or(false);

                if branch_exists {
                    continue;
                }

                self.run_git(
                    &project_path,
                    ["branch", "--track", &branch_name, &upstream_ref],
                )
                .with_context(|| format!("failed to create branch '{branch_name}'"))?;

                self.run_git(
                    &project_path,
                    [
                        "worktree",
                        "add",
                        worktree_path
                            .to_str()
                            .ok_or_else(|| anyhow!("invalid worktree path"))?,
                        &branch_name,
                    ],
                )
                .with_context(|| {
                    format!("failed to create worktree at {}", worktree_path.display())
                })?;

                return Ok(CreatedWorkspace {
                    workspace_name,
                    branch_name,
                    worktree_path,
                });
            }

            Err(anyhow!(
                "failed to generate a unique workspace name after retries"
            ))
        })();

        result.map_err(|e| format!("{e:#}"))
    }

    fn open_workspace_in_ide(&self, worktree_path: PathBuf) -> Result<(), String> {
        let result: anyhow::Result<()> = (|| {
            if !worktree_path.exists() {
                return Err(anyhow!(
                    "workspace path does not exist: {}",
                    worktree_path.display()
                ));
            }

            #[cfg(target_os = "macos")]
            {
                let status = Command::new("open")
                    .args(["-a", "Zed"])
                    .arg(&worktree_path)
                    .status()
                    .context("failed to spawn 'open -a Zed'")?;
                if !status.success() {
                    return Err(anyhow!("'open -a Zed' exited with status: {status}"));
                }
                Ok(())
            }

            #[cfg(not(target_os = "macos"))]
            {
                let _ = worktree_path;
                Err(anyhow!("open in IDE is only supported on macOS for now"))
            }
        })();

        result.map_err(|e| format!("{e:#}"))
    }

    fn archive_workspace(
        &self,
        project_path: PathBuf,
        worktree_path: PathBuf,
    ) -> Result<(), String> {
        let result: anyhow::Result<()> = (|| {
            let path_str = worktree_path
                .to_str()
                .ok_or_else(|| anyhow!("invalid worktree path"))?;
            self.run_git(&project_path, ["worktree", "remove", "--force", path_str])
                .with_context(|| {
                    format!("failed to remove worktree at {}", worktree_path.display())
                })?;
            Ok(())
        })();
        result.map_err(|e| format!("{e:#}"))
    }

    fn ensure_conversation(
        &self,
        project_slug: String,
        workspace_name: String,
        thread_id: u64,
    ) -> Result<(), String> {
        self.ensure_conversation_internal(project_slug, workspace_name, thread_id)
            .map_err(|e| format!("{e:#}"))
    }

    fn list_conversation_threads(
        &self,
        project_slug: String,
        workspace_name: String,
    ) -> Result<Vec<luban_domain::ConversationThreadMeta>, String> {
        self.sqlite
            .list_conversation_threads(project_slug, workspace_name)
            .map_err(|e| format!("{e:#}"))
    }

    fn load_conversation(
        &self,
        project_slug: String,
        workspace_name: String,
        thread_id: u64,
    ) -> Result<ConversationSnapshot, String> {
        self.load_conversation_internal(project_slug, workspace_name, thread_id)
            .map_err(|e| format!("{e:#}"))
    }

    fn store_context_image(
        &self,
        project_slug: String,
        workspace_name: String,
        image: ContextImage,
    ) -> Result<AttachmentRef, String> {
        let byte_len = image.bytes.len() as u64;
        let stored: anyhow::Result<(String, PathBuf)> = self.store_context_bytes(
            &project_slug,
            &workspace_name,
            &image.bytes,
            &image.extension,
        );
        let (id, stored_path) = stored.map_err(|e| format!("{e:#}"))?;
        let _ = self.maybe_store_context_image_thumbnail(
            &project_slug,
            &workspace_name,
            &stored_path,
            &image.bytes,
        );
        let extension = stored_path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("png")
            .to_owned();
        Ok(AttachmentRef {
            id,
            kind: AttachmentKind::Image,
            name: format!("image.{extension}"),
            extension,
            mime: None,
            byte_len,
        })
    }

    fn store_context_text(
        &self,
        project_slug: String,
        workspace_name: String,
        text: String,
        extension: String,
    ) -> Result<AttachmentRef, String> {
        let bytes = text.into_bytes();
        let byte_len = bytes.len() as u64;
        let result: anyhow::Result<(String, PathBuf)> =
            self.store_context_bytes(&project_slug, &workspace_name, &bytes, &extension);
        let (id, stored_path) = result.map_err(|e| format!("{e:#}"))?;
        let extension = stored_path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("txt")
            .to_owned();
        Ok(AttachmentRef {
            id,
            kind: AttachmentKind::Text,
            name: format!("text.{extension}"),
            extension,
            mime: None,
            byte_len,
        })
    }

    fn store_context_file(
        &self,
        project_slug: String,
        workspace_name: String,
        source_path: PathBuf,
    ) -> Result<AttachmentRef, String> {
        let name = source_path
            .file_name()
            .and_then(|s| s.to_str())
            .unwrap_or("file")
            .to_owned();
        let result: anyhow::Result<(String, String, u64, PathBuf)> =
            self.store_context_file_internal(&project_slug, &workspace_name, &source_path);
        let (id, extension, byte_len, _path) = result.map_err(|e| format!("{e:#}"))?;
        Ok(AttachmentRef {
            id,
            kind: AttachmentKind::File,
            name,
            extension,
            mime: None,
            byte_len,
        })
    }

    fn record_context_item(
        &self,
        project_slug: String,
        workspace_name: String,
        attachment: AttachmentRef,
        created_at_unix_ms: u64,
    ) -> Result<u64, String> {
        self.sqlite
            .insert_context_item(project_slug, workspace_name, attachment, created_at_unix_ms)
            .map_err(|e| format!("{e:#}"))
    }

    fn list_context_items(
        &self,
        project_slug: String,
        workspace_name: String,
    ) -> Result<Vec<luban_domain::ContextItem>, String> {
        self.sqlite
            .list_context_items(project_slug, workspace_name)
            .map_err(|e| format!("{e:#}"))
    }

    fn delete_context_item(
        &self,
        project_slug: String,
        workspace_name: String,
        context_id: u64,
    ) -> Result<(), String> {
        self.sqlite
            .delete_context_item(project_slug, workspace_name, context_id)
            .map_err(|e| format!("{e:#}"))
    }

    fn run_agent_turn_streamed(
        &self,
        request: RunAgentTurnRequest,
        cancel: Arc<AtomicBool>,
        on_event: Arc<dyn Fn(CodexThreadEvent) + Send + Sync>,
    ) -> Result<(), String> {
        let RunAgentTurnRequest {
            project_slug,
            workspace_name,
            worktree_path,
            thread_local_id,
            thread_id,
            prompt,
            attachments,
            model,
            model_reasoning_effort,
        } = request;

        let turn_started_at = Instant::now();
        let turn_scope_id = generate_turn_scope_id();
        let duration_appended = Arc::new(AtomicBool::new(false));
        let mut appended_item_ids = HashSet::<String>::new();

        let result: anyhow::Result<()> = (|| {
            self.ensure_conversation_internal(
                project_slug.clone(),
                workspace_name.clone(),
                thread_local_id,
            )?;

            let mut existing_thread_id = self.sqlite.get_conversation_thread_id(
                project_slug.clone(),
                workspace_name.clone(),
                thread_local_id,
            )?;
            if thread_local_id == 1
                && existing_thread_id.is_none()
                && let Some(legacy) =
                    self.load_conversation_legacy(&project_slug, &workspace_name)?
                && let Some(legacy_thread_id) = legacy.thread_id
            {
                self.sqlite.set_conversation_thread_id(
                    project_slug.clone(),
                    workspace_name.clone(),
                    thread_local_id,
                    legacy_thread_id.clone(),
                )?;
                existing_thread_id = Some(legacy_thread_id);
            }

            self.sqlite.append_conversation_entries(
                project_slug.clone(),
                workspace_name.clone(),
                thread_local_id,
                vec![ConversationEntry::UserMessage {
                    text: prompt.clone(),
                    attachments: attachments.clone(),
                }],
            )?;

            let resolved_thread_id = thread_id.or(existing_thread_id);
            let blobs_dir = self.context_blobs_dir(&project_slug, &workspace_name);
            let image_paths = attachments
                .iter()
                .filter(|a| a.kind == AttachmentKind::Image)
                .map(|a| blobs_dir.join(format!("{}.{}", a.id, a.extension)))
                .collect::<Vec<_>>();

            let mut turn_error: Option<String> = None;
            let mut transient_error_seq: u64 = 0;
            let duration_appended_for_events = duration_appended.clone();

            self.run_codex_turn_streamed_via_cli(
                CodexTurnParams {
                    thread_id: resolved_thread_id,
                    worktree_path: worktree_path.clone(),
                    prompt: prompt.clone(),
                    image_paths,
                    model: model.clone(),
                    model_reasoning_effort: model_reasoning_effort.clone(),
                    sandbox_mode: None,
                },
                cancel.clone(),
                |event| {
                    let mut events_to_process = Vec::with_capacity(1);
                    match &event {
                        CodexThreadEvent::Error { message }
                            if is_transient_reconnect_notice(message) =>
                        {
                            transient_error_seq = transient_error_seq.saturating_add(1);
                            events_to_process.push(CodexThreadEvent::ItemCompleted {
                                item: CodexThreadItem::Error {
                                    id: format!("transient-error-{transient_error_seq}"),
                                    message: message.clone(),
                                },
                            });
                        }
                        _ => events_to_process.push(event),
                    }

                    for event in events_to_process {
                        let event = qualify_event(&turn_scope_id, event);
                        on_event(event.clone());

                        match &event {
                            CodexThreadEvent::ThreadStarted { thread_id } => {
                                self.sqlite.set_conversation_thread_id(
                                    project_slug.clone(),
                                    workspace_name.clone(),
                                    thread_local_id,
                                    thread_id.clone(),
                                )?;
                            }
                            CodexThreadEvent::ItemCompleted { item } => {
                                let id = codex_item_id(item).to_owned();
                                if appended_item_ids.insert(id) {
                                    self.sqlite.append_conversation_entries(
                                        project_slug.clone(),
                                        workspace_name.clone(),
                                        thread_local_id,
                                        vec![ConversationEntry::CodexItem {
                                            item: Box::new(item.clone()),
                                        }],
                                    )?;
                                }
                            }
                            CodexThreadEvent::TurnCompleted { usage } => {
                                let _ = usage;
                                if duration_appended_for_events
                                    .compare_exchange(
                                        false,
                                        true,
                                        Ordering::SeqCst,
                                        Ordering::SeqCst,
                                    )
                                    .is_ok()
                                {
                                    let duration_ms = turn_started_at.elapsed().as_millis() as u64;
                                    self.sqlite.append_conversation_entries(
                                        project_slug.clone(),
                                        workspace_name.clone(),
                                        thread_local_id,
                                        vec![ConversationEntry::TurnDuration { duration_ms }],
                                    )?;
                                    on_event(CodexThreadEvent::TurnDuration { duration_ms });
                                }
                            }
                            CodexThreadEvent::TurnFailed { error } => {
                                if turn_error.is_none() {
                                    turn_error = Some(error.message.clone());
                                }
                                self.sqlite.append_conversation_entries(
                                    project_slug.clone(),
                                    workspace_name.clone(),
                                    thread_local_id,
                                    vec![ConversationEntry::TurnError {
                                        message: error.message.clone(),
                                    }],
                                )?;
                                if duration_appended_for_events
                                    .compare_exchange(
                                        false,
                                        true,
                                        Ordering::SeqCst,
                                        Ordering::SeqCst,
                                    )
                                    .is_ok()
                                {
                                    let duration_ms = turn_started_at.elapsed().as_millis() as u64;
                                    self.sqlite.append_conversation_entries(
                                        project_slug.clone(),
                                        workspace_name.clone(),
                                        thread_local_id,
                                        vec![ConversationEntry::TurnDuration { duration_ms }],
                                    )?;
                                    on_event(CodexThreadEvent::TurnDuration { duration_ms });
                                }
                            }
                            CodexThreadEvent::Error { message } => {
                                if turn_error.is_none() {
                                    turn_error = Some(message.clone());
                                }
                                self.sqlite.append_conversation_entries(
                                    project_slug.clone(),
                                    workspace_name.clone(),
                                    thread_local_id,
                                    vec![ConversationEntry::TurnError {
                                        message: message.clone(),
                                    }],
                                )?;
                                if duration_appended_for_events
                                    .compare_exchange(
                                        false,
                                        true,
                                        Ordering::SeqCst,
                                        Ordering::SeqCst,
                                    )
                                    .is_ok()
                                {
                                    let duration_ms = turn_started_at.elapsed().as_millis() as u64;
                                    self.sqlite.append_conversation_entries(
                                        project_slug.clone(),
                                        workspace_name.clone(),
                                        thread_local_id,
                                        vec![ConversationEntry::TurnDuration { duration_ms }],
                                    )?;
                                    on_event(CodexThreadEvent::TurnDuration { duration_ms });
                                }
                            }
                            CodexThreadEvent::TurnStarted
                            | CodexThreadEvent::TurnDuration { .. }
                            | CodexThreadEvent::ItemStarted { .. }
                            | CodexThreadEvent::ItemUpdated { .. } => {}
                        }
                    }

                    Ok(())
                },
            )?;

            if cancel.load(Ordering::SeqCst) {
                if duration_appended
                    .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
                    .is_ok()
                {
                    let duration_ms = turn_started_at.elapsed().as_millis() as u64;
                    self.sqlite.append_conversation_entries(
                        project_slug.clone(),
                        workspace_name.clone(),
                        thread_local_id,
                        vec![ConversationEntry::TurnDuration { duration_ms }],
                    )?;
                    on_event(CodexThreadEvent::TurnDuration { duration_ms });
                }
                self.sqlite.append_conversation_entries(
                    project_slug.clone(),
                    workspace_name.clone(),
                    thread_local_id,
                    vec![ConversationEntry::TurnCanceled],
                )?;
                return Ok(());
            }

            if let Some(message) = turn_error {
                return Err(anyhow!("{message}"));
            }

            Ok(())
        })();

        if let Err(err) = &result {
            if duration_appended
                .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
                .is_ok()
            {
                let duration_ms = turn_started_at.elapsed().as_millis() as u64;
                let _ = self.sqlite.append_conversation_entries(
                    project_slug.clone(),
                    workspace_name.clone(),
                    thread_local_id,
                    vec![ConversationEntry::TurnDuration { duration_ms }],
                );
                on_event(CodexThreadEvent::TurnDuration { duration_ms });
            }
            let _ = self.sqlite.append_conversation_entries(
                project_slug.clone(),
                workspace_name.clone(),
                thread_local_id,
                vec![ConversationEntry::TurnError {
                    message: format!("{err:#}"),
                }],
            );
        }

        result.map_err(|e| format!("{e:#}"))
    }

    fn gh_is_authorized(&self) -> Result<bool, String> {
        let output = Command::new("gh")
            .args(["auth", "status", "-h", "github.com"])
            .output();

        Ok(output.ok().map(|o| o.status.success()).unwrap_or(false))
    }

    fn gh_pull_request_info(
        &self,
        worktree_path: PathBuf,
    ) -> Result<Option<PullRequestInfo>, String> {
        #[derive(serde::Deserialize)]
        struct GhPullRequestCheck {
            #[serde(default)]
            bucket: String,
        }

        #[derive(serde::Deserialize)]
        struct GhPullRequestView {
            number: u64,
            #[serde(default, rename = "isDraft")]
            is_draft: bool,
            #[serde(default)]
            state: String,
            #[serde(default, rename = "mergeStateStatus")]
            merge_state_status: String,
            #[serde(default, rename = "reviewDecision")]
            review_decision: String,
        }

        fn checks_ci_state(checks: &[GhPullRequestCheck]) -> Option<PullRequestCiState> {
            let mut any_pending = false;
            let mut any_fail = false;
            let mut any_pass = false;
            for check in checks {
                match check.bucket.as_str() {
                    "fail" => any_fail = true,
                    "pending" => any_pending = true,
                    "pass" => any_pass = true,
                    _ => {}
                }
            }

            if any_fail {
                return Some(PullRequestCiState::Failure);
            }
            if any_pending {
                return Some(PullRequestCiState::Pending);
            }
            if any_pass {
                return Some(PullRequestCiState::Success);
            }
            None
        }

        fn is_merge_ready(
            pr_state: PullRequestState,
            is_draft: bool,
            merge_state_status: &str,
            review_decision: &str,
            ci_state: Option<PullRequestCiState>,
        ) -> bool {
            if pr_state != PullRequestState::Open {
                return false;
            }
            if is_draft {
                return false;
            }
            if review_decision != "APPROVED" {
                return false;
            }
            if ci_state != Some(PullRequestCiState::Success) {
                return false;
            }
            matches!(merge_state_status, "CLEAN" | "HAS_HOOKS")
        }

        let output = Command::new("gh")
            .args([
                "pr",
                "view",
                "--json",
                "number,isDraft,state,mergeStateStatus,reviewDecision",
            ])
            .current_dir(&worktree_path)
            .output();

        let Ok(output) = output else {
            return Ok(None);
        };
        if !output.status.success() {
            return Ok(None);
        }

        let Ok(value) = serde_json::from_slice::<GhPullRequestView>(&output.stdout) else {
            return Ok(None);
        };

        let state = match value.state.as_str() {
            "OPEN" => PullRequestState::Open,
            "CLOSED" => PullRequestState::Closed,
            "MERGED" => PullRequestState::Merged,
            _ => PullRequestState::Open,
        };

        let checks_output = Command::new("gh")
            .args(["pr", "checks", "--required", "--json", "bucket"])
            .current_dir(&worktree_path)
            .output();

        let (checks_known, checks) = match checks_output {
            Ok(output) if output.status.success() => (
                true,
                serde_json::from_slice::<Vec<GhPullRequestCheck>>(&output.stdout)
                    .unwrap_or_default(),
            ),
            _ => (false, Vec::new()),
        };

        let ci_state = if !checks_known {
            None
        } else if checks.is_empty() {
            Some(PullRequestCiState::Success)
        } else {
            checks_ci_state(&checks)
        };
        let merge_ready = is_merge_ready(
            state,
            value.is_draft,
            &value.merge_state_status,
            &value.review_decision,
            ci_state,
        );

        Ok(Some(PullRequestInfo {
            number: value.number,
            is_draft: value.is_draft,
            state,
            ci_state,
            merge_ready,
        }))
    }

    fn gh_open_pull_request(&self, worktree_path: PathBuf) -> Result<(), String> {
        let output = Command::new("gh")
            .args(["pr", "view", "--web"])
            .current_dir(worktree_path)
            .output();

        let Ok(output) = output else {
            return Err("Failed to run gh".to_owned());
        };
        if output.status.success() {
            return Ok(());
        }

        let stderr = String::from_utf8_lossy(&output.stderr).trim().to_owned();
        if stderr.is_empty() {
            Err("Failed to open pull request".to_owned())
        } else {
            Err(stderr)
        }
    }

    fn gh_open_pull_request_failed_action(&self, worktree_path: PathBuf) -> Result<(), String> {
        #[derive(serde::Deserialize)]
        struct GhPullRequestCheck {
            #[serde(default)]
            bucket: String,
            #[serde(default)]
            link: String,
        }

        let result: anyhow::Result<()> = (|| {
            let output = Command::new("gh")
                .args(["pr", "checks", "--required", "--json", "bucket,link"])
                .current_dir(&worktree_path)
                .output()
                .context("failed to run 'gh pr checks'")?;

            let checks = serde_json::from_slice::<Vec<GhPullRequestCheck>>(&output.stdout)
                .unwrap_or_default();
            if let Some(url) = checks
                .iter()
                .find(|check| check.bucket == "fail" && !check.link.is_empty())
                .map(|check| check.link.as_str())
            {
                return self.open_url(url);
            }

            let output = Command::new("gh")
                .args(["pr", "checks", "--web"])
                .current_dir(&worktree_path)
                .output()
                .context("failed to run 'gh pr checks --web'")?;
            if output.status.success() {
                return Ok(());
            }

            let stderr = String::from_utf8_lossy(&output.stderr).trim().to_owned();
            if stderr.is_empty() {
                Err(anyhow!("failed to open pull request checks"))
            } else {
                Err(anyhow!("{stderr}"))
            }
        })();

        result.map_err(|e| format!("{e:#}"))
    }

    fn task_preview(&self, input: String) -> Result<luban_domain::TaskDraft, String> {
        task::task_preview(self, input).map_err(|e| format!("{e:#}"))
    }

    fn task_prepare_project(&self, spec: luban_domain::TaskProjectSpec) -> Result<PathBuf, String> {
        task::task_prepare_project(self, spec).map_err(|e| format!("{e:#}"))
    }

    fn project_identity(&self, path: PathBuf) -> Result<luban_domain::ProjectIdentity, String> {
        let result: anyhow::Result<luban_domain::ProjectIdentity> = (|| {
            if !path.exists() {
                return Ok(luban_domain::ProjectIdentity {
                    root_path: path,
                    github_repo: None,
                });
            }

            let root = self.repo_root(&path).unwrap_or(path);
            let remote = self.select_remote_best_effort(&root).unwrap_or(None);
            let github_repo = if let Some(remote) = remote {
                let url = self.run_git(&root, ["remote", "get-url", &remote]).ok();
                url.and_then(|u| Self::github_repo_id_from_remote_url(&u))
            } else {
                None
            };

            Ok(luban_domain::ProjectIdentity {
                root_path: root,
                github_repo,
            })
        })();

        result.map_err(|e| format!("{e:#}"))
    }
}

impl GitWorkspaceService {
    fn open_url(&self, url: &str) -> anyhow::Result<()> {
        #[cfg(target_os = "macos")]
        {
            let status = Command::new("open")
                .arg(url)
                .status()
                .context("failed to spawn 'open'")?;
            if !status.success() {
                return Err(anyhow!("'open' exited with status: {status}"));
            }
            Ok(())
        }

        #[cfg(target_os = "windows")]
        {
            let status = Command::new("cmd")
                .args(["/C", "start", "", url])
                .status()
                .context("failed to spawn 'cmd /C start'")?;
            if !status.success() {
                return Err(anyhow!("'cmd /C start' exited with status: {status}"));
            }
            Ok(())
        }

        #[cfg(all(not(target_os = "macos"), not(target_os = "windows")))]
        {
            let status = Command::new("xdg-open")
                .arg(url)
                .status()
                .context("failed to spawn 'xdg-open'")?;
            if !status.success() {
                return Err(anyhow!("'xdg-open' exited with status: {status}"));
            }
            Ok(())
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::{Path, PathBuf};

    static ENV_LOCK: std::sync::Mutex<()> = std::sync::Mutex::new(());

    fn lock_env() -> std::sync::MutexGuard<'static, ()> {
        ENV_LOCK.lock().unwrap_or_else(|err| err.into_inner())
    }

    fn run_git(repo_path: &Path, args: &[&str]) -> std::process::Output {
        Command::new("git")
            .args(args)
            .current_dir(repo_path)
            .output()
            .expect("git should spawn")
    }

    fn assert_git_success(repo_path: &Path, args: &[&str]) {
        let output = run_git(repo_path, args);
        if !output.status.success() {
            panic!(
                "git failed ({:?}):\nstdout:\n{}\nstderr:\n{}",
                args,
                String::from_utf8_lossy(&output.stdout).trim(),
                String::from_utf8_lossy(&output.stderr).trim()
            );
        }
    }

    #[test]
    fn transient_reconnect_notice_detection_is_stable() {
        assert!(is_transient_reconnect_notice("reconnecting ...1/5"));
        assert!(is_transient_reconnect_notice("Reconnecting (12/100)"));
        assert!(!is_transient_reconnect_notice("retry/reconnect"));
        assert!(!is_transient_reconnect_notice("connection failed"));
        assert!(!is_transient_reconnect_notice("reconnecting soon"));
    }

    #[test]
    fn codex_runner_reports_missing_executable() {
        let _guard = lock_env();

        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir = std::env::temp_dir().join(format!(
            "luban-missing-codex-check-{}-{}",
            std::process::id(),
            unique
        ));
        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        let missing_codex = base_dir.join("missing-codex-bin");
        unsafe {
            std::env::set_var(paths::LUBAN_CODEX_BIN_ENV, missing_codex.as_os_str());
        }

        let sqlite =
            SqliteStore::new(paths::sqlite_path(&base_dir)).expect("sqlite init should work");
        let service = GitWorkspaceService {
            worktrees_root: paths::worktrees_root(&base_dir),
            conversations_root: paths::conversations_root(&base_dir),
            sqlite,
        };

        let err = service
            .run_codex_turn_streamed_via_cli(
                CodexTurnParams {
                    thread_id: None,
                    worktree_path: base_dir.clone(),
                    prompt: "Hi".to_owned(),
                    image_paths: Vec::new(),
                    model: None,
                    model_reasoning_effort: None,
                    sandbox_mode: None,
                },
                Arc::new(AtomicBool::new(false)),
                |_event| Ok(()),
            )
            .expect_err("missing codex executable should fail");

        unsafe {
            std::env::remove_var(paths::LUBAN_CODEX_BIN_ENV);
        }

        assert!(err.to_string().contains("missing codex executable"));

        drop(service);
        let _ = std::fs::remove_dir_all(&base_dir);
    }

    #[test]
    fn tests_do_not_use_production_db_by_default() {
        let _guard = lock_env();

        let prev = std::env::var_os(paths::LUBAN_ROOT_ENV);
        unsafe {
            std::env::remove_var(paths::LUBAN_ROOT_ENV);
        }

        let root = resolve_luban_root().expect("test root should resolve");
        assert!(
            root.to_string_lossy().contains("luban-test-"),
            "expected test root under temp dir, got {}",
            root.display()
        );

        if let Some(prev) = prev {
            unsafe {
                std::env::set_var(paths::LUBAN_ROOT_ENV, prev);
            }
        }
    }

    #[test]
    fn luban_root_env_overrides_default_root() {
        let _guard = lock_env();

        let prev = std::env::var_os(paths::LUBAN_ROOT_ENV);
        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir =
            std::env::temp_dir().join(format!("luban-root-env-{}-{}", std::process::id(), unique));
        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        unsafe {
            std::env::set_var(paths::LUBAN_ROOT_ENV, base_dir.as_os_str());
        }

        let service = GitWorkspaceService::new_with_options(SqliteStoreOptions::default())
            .expect("service should init");
        service
            .sqlite
            .load_app_state()
            .expect("sqlite queries should work");

        let expected_db = paths::sqlite_path(&base_dir);
        assert!(
            expected_db.exists(),
            "expected sqlite db at {}, but it was not created",
            expected_db.display()
        );

        drop(service);
        if let Some(prev) = prev {
            unsafe {
                std::env::set_var(paths::LUBAN_ROOT_ENV, prev);
            }
        } else {
            unsafe {
                std::env::remove_var(paths::LUBAN_ROOT_ENV);
            }
        }
        let _ = std::fs::remove_dir_all(&base_dir);
    }

    #[test]
    fn codex_item_ids_are_scoped_per_turn() {
        let item = CodexThreadItem::AgentMessage {
            id: "item_0".to_owned(),
            text: "Hi".to_owned(),
        };
        let a = qualify_codex_item("turn-a", item.clone());
        let b = qualify_codex_item("turn-b", item);
        assert_eq!(codex_item_id(&a), "turn-a/item_0");
        assert_eq!(codex_item_id(&b), "turn-b/item_0");
        let a2 = qualify_codex_item("turn-a", a);
        assert_eq!(codex_item_id(&a2), "turn-a/item_0");
    }

    #[test]
    fn worktree_remove_force_allows_dirty_worktree() {
        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir = std::env::temp_dir().join(format!(
            "luban-worktree-remove-force-{}-{}",
            std::process::id(),
            unique
        ));

        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        let repo_path = base_dir.join("repo");
        std::fs::create_dir_all(&repo_path).expect("repo dir should be created");

        assert_git_success(&repo_path, &["init"]);
        assert_git_success(&repo_path, &["config", "user.name", "Test User"]);
        assert_git_success(&repo_path, &["config", "user.email", "test@example.com"]);

        let tracked_file = repo_path.join("tracked.txt");
        std::fs::write(&tracked_file, "hello\n").expect("write should succeed");
        assert_git_success(&repo_path, &["add", "."]);
        assert_git_success(&repo_path, &["commit", "-m", "init"]);

        let worktree_path = base_dir.join("worktree");
        let branch_name = format!("luban-test-branch-{unique}");
        assert_git_success(
            &repo_path,
            &[
                "worktree",
                "add",
                "-b",
                &branch_name,
                worktree_path
                    .to_str()
                    .expect("worktree path should be utf-8"),
            ],
        );

        let dirty_file = worktree_path.join("tracked.txt");
        std::fs::write(&dirty_file, "hello\ndirty\n").expect("write should succeed");

        let no_force = run_git(
            &repo_path,
            &[
                "worktree",
                "remove",
                worktree_path
                    .to_str()
                    .expect("worktree path should be utf-8"),
            ],
        );
        assert!(
            !no_force.status.success(),
            "worktree remove without --force should fail for dirty worktree"
        );

        let sqlite =
            SqliteStore::new(paths::sqlite_path(&base_dir)).expect("sqlite init should work");
        let service = GitWorkspaceService {
            worktrees_root: paths::worktrees_root(&base_dir),
            conversations_root: paths::conversations_root(&base_dir),
            sqlite,
        };

        ProjectWorkspaceService::archive_workspace(
            &service,
            repo_path.clone(),
            worktree_path.clone(),
        )
        .expect("archive_workspace should remove dirty worktree with --force");
        assert!(!worktree_path.exists(), "worktree path should be removed");

        drop(service);
        let _ = std::fs::remove_dir_all(&base_dir);
    }

    fn stored_blob_path(
        service: &GitWorkspaceService,
        project_slug: &str,
        workspace_name: &str,
        attachment: &AttachmentRef,
    ) -> PathBuf {
        service
            .context_blobs_dir(project_slug, workspace_name)
            .join(format!("{}.{}", attachment.id, attachment.extension))
    }

    #[test]
    fn context_files_are_content_addressed_and_preserve_display_name() {
        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir = std::env::temp_dir().join(format!(
            "luban-context-file-name-{}-{}",
            std::process::id(),
            unique
        ));

        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        let sqlite =
            SqliteStore::new(paths::sqlite_path(&base_dir)).expect("sqlite init should work");
        let service = GitWorkspaceService {
            worktrees_root: paths::worktrees_root(&base_dir),
            conversations_root: paths::conversations_root(&base_dir),
            sqlite,
        };

        let source = base_dir.join("abc.png");
        let bytes = b"not-a-real-png";
        std::fs::write(&source, bytes).expect("write should succeed");

        let stored = ProjectWorkspaceService::store_context_file(
            &service,
            "proj".to_owned(),
            "main".to_owned(),
            source,
        )
        .expect("store_context_file should succeed");

        assert_eq!(stored.name, "abc.png");
        assert_eq!(stored.extension, "png");
        assert_eq!(stored.id, blake3::hash(bytes).to_hex().to_string());
        assert!(
            stored_blob_path(&service, "proj", "main", &stored).exists(),
            "stored blob should exist"
        );

        drop(service);
        let _ = std::fs::remove_dir_all(&base_dir);
    }

    #[test]
    fn context_images_are_content_addressed() {
        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir = std::env::temp_dir().join(format!(
            "luban-context-image-name-{}-{}",
            std::process::id(),
            unique
        ));

        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        let sqlite =
            SqliteStore::new(paths::sqlite_path(&base_dir)).expect("sqlite init should work");
        let service = GitWorkspaceService {
            worktrees_root: paths::worktrees_root(&base_dir),
            conversations_root: paths::conversations_root(&base_dir),
            sqlite,
        };

        let stored = ProjectWorkspaceService::store_context_image(
            &service,
            "proj".to_owned(),
            "main".to_owned(),
            ContextImage {
                extension: "png".to_owned(),
                bytes: b"not-a-real-png".to_vec(),
            },
        )
        .expect("store_context_image should succeed");

        assert_eq!(stored.name, "image.png");
        assert_eq!(stored.extension, "png");
        assert_eq!(
            stored.id,
            blake3::hash(b"not-a-real-png").to_hex().to_string()
        );
        assert!(
            stored_blob_path(&service, "proj", "main", &stored).exists(),
            "stored blob should exist"
        );

        drop(service);
        let _ = std::fs::remove_dir_all(&base_dir);
    }

    #[test]
    fn context_images_store_thumbnail_alongside_original() {
        let unique = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("time should be valid")
            .as_nanos();
        let base_dir = std::env::temp_dir().join(format!(
            "luban-context-image-thumb-{}-{}",
            std::process::id(),
            unique
        ));

        std::fs::create_dir_all(&base_dir).expect("temp dir should be created");

        let sqlite =
            SqliteStore::new(paths::sqlite_path(&base_dir)).expect("sqlite init should work");
        let service = GitWorkspaceService {
            worktrees_root: paths::worktrees_root(&base_dir),
            conversations_root: paths::conversations_root(&base_dir),
            sqlite,
        };

        let img = image::RgbImage::from_fn(1200, 800, |x, y| {
            image::Rgb([(x % 256) as u8, (y % 256) as u8, ((x + y) % 256) as u8])
        });
        let mut png = Vec::new();
        image::DynamicImage::ImageRgb8(img)
            .write_to(&mut std::io::Cursor::new(&mut png), image::ImageFormat::Png)
            .expect("encode png");

        let stored = ProjectWorkspaceService::store_context_image(
            &service,
            "proj".to_owned(),
            "main".to_owned(),
            ContextImage {
                extension: "png".to_owned(),
                bytes: png,
            },
        )
        .expect("store_context_image should succeed");

        let stored_path = stored_blob_path(&service, "proj", "main", &stored);
        let thumb = stored_path.with_file_name(format!("{}-thumb.png", stored.id));

        assert!(stored_path.exists(), "stored path should exist");
        assert!(thumb.exists(), "thumbnail path should exist");

        let thumb_bytes = std::fs::read(&thumb).expect("read thumbnail");
        let thumb_img = image::load_from_memory(&thumb_bytes).expect("decode thumbnail");
        assert!(
            thumb_img.width() <= 360 && thumb_img.height() <= 220,
            "expected thumbnail to be constrained: {}x{}",
            thumb_img.width(),
            thumb_img.height()
        );

        let stored_len = std::fs::metadata(&stored_path).expect("stat stored").len();
        let thumb_len = std::fs::metadata(&thumb).expect("stat thumb").len();
        assert!(
            thumb_len <= stored_len,
            "expected thumbnail to not exceed original size (thumb={thumb_len}, stored={stored_len})"
        );

        drop(service);
        let _ = std::fs::remove_dir_all(&base_dir);
    }
}
